# Assignment 3

## Part 1

Implemented the following:

- Self Attention
- Next Token Prediction
- Generation of Sequence

## Part 2

Link to the [Kaggle Competition](https://www.kaggle.com/competitions/11-785-hw3p2-f24/leaderboard?search=veri)

The competition focused on Speech Recognition using a Transformer Model. Model Details:

- Speech Embedding: CNN Subsampling + BiLSTM + Downsample
- Transformer Encoder: Multi-Head Self Attention + Feed Forward
- Transformer Decoder: Multi-Head Self Attention + Feed Forward + Cross Attention
